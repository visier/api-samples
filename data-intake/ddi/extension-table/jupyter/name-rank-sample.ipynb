{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bdd0ef9-bd98-4ef2-8e25-056c8e6b8485",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Enriching the Visier Model\n",
    "## Overview\n",
    "In this Jupyter notebook sample, learn how to use the Direct Data Intake (DDI) API in Extension mode to extend the data in a Visier object that is primarily loaded using other data transfer methods.\n",
    "This sample's purpose is to show how to call Visier's public APIs to query source data, combine source data with an external data set, and then send back the combined data to Visier.\n",
    "\n",
    "In this sample, we combine Employee data in Visier with the United States government Social Security Administration's (SSA) [publicly available name data](https://www.ssa.gov/oact/babynames/limits.html) to populate a new Employee property called Name_Rank.\n",
    "\n",
    "### Prerequisites\n",
    "Before running this sample, do the following:\n",
    "1. In your Visier tenant, create a simple numeric property with the object name `Name_Rank` on the `Employee` object in Visier. Publish the property to production.\n",
    "1. In your Visier tenant, create a profile and assign it to your API user with the following capabilities and additional capabilities:\n",
    "   1. Data: Write, API\n",
    "   1. Model: Read, API\n",
    "   1. Direct Publish\n",
    "   1. Legacy API Access\n",
    "   1. Manage Jobs\n",
    "   1. Upload Data\n",
    "1. Defined an `.env` file as described in the [Python Connector documentation](https://github.com/visier/connector-python#jupyter-basic-authentication-example)\n",
    "1. Downloaded the [National Data file](https://www.ssa.gov/oact/babynames/names.zip) and extract file `yob2022.txt`.\n",
    "1. Copy `yob2022.txt` into a directory named `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902780aa-da53-4911-8f7e-c8a4ef61dddd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Extension Data\n",
    "We use the [pandas](https://pandas.pydata.org/docs/) library both to represent data sets through [Dataframes](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) as well as for file handling. We load data with the [read_csv](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) method because the source files are comma-separated.\n",
    "In the following code, we provide a header with names that exactly match the names of Visier properties. We provide headers in the code because the source file doesn't contain a header row, so we must provide a header to align with Visier's property names. In addition to headers, we perform transformations to sort the results by occurrence of each name and assign the name rank based on the row number of the sorted lists.\n",
    "We also define an index to facilitate a subsequent join-operation with Visier `Employee` data.\n",
    "\n",
    "The SSA designates names as Female or Male. From this data, we create two distinct SSA name data sets: `f_names` and `m_names`.\n",
    "\n",
    "(We will address the simplification of Visier's gender dimension later on, when we actually do that in the code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "59a0d7cc-c739-43a4-a761-c363fe4038aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_and_index(df, gender):\n",
    "    df.loc[df['Gender'] == gender]\n",
    "    df['Name_Rank'] = df.reset_index().index + 1\n",
    "    return df.set_index(['First_Name', 'Gender'])\n",
    "\n",
    "names = pd.read_csv('data/yob2022.txt', header=0, names=['First_Name', 'Gender', 'Count'])\n",
    "names.sort_values(inplace=True, by='Count', ascending=False)\n",
    "f_names = filter_and_index(names, 'F')\n",
    "m_names = filter_and_index(names, 'M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de6df0f-fb1c-46c7-9ebe-b31c1f574e57",
   "metadata": {},
   "source": [
    "## Query for Employee Data\n",
    "Next, we instantiate the Visier Python Connector. To do so, we read the credentials, build an `auth` object to use to sign into Visier, and then get a session object, `s`.\n",
    "Because we need to execute a Visier SQL-like query to get the list of employees whose name we want to rank in this sample, we import the `QueryApiClient`.\n",
    "\n",
    "The SSA designates gender into two categories: Female and Male. Visier's Gender dimension contains more than two genders, including Woman, Man, Non-Binary, and more. To align Visier with SSA's data categorization, we run two SQL-like queries: one where `isFemale=TRUE` and one where `isMale=TRUE`\n",
    ". This allows us to ascribe gender keys from the SSA data set to the data in Visier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b8fe6ec-4936-4db6-820f-f4da002daf8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from dotenv import dotenv_values\n",
    "from visier.connector import VisierSession, make_auth\n",
    "from visier.api import QueryApiClient\n",
    "\n",
    "env_creds=dotenv_values()\n",
    "auth = make_auth(env_values=env_creds)\n",
    "\n",
    "def mk_df(client, query):\n",
    "    \"\"\"Run a list query and return the results as a Pandas DataFrame.\n",
    "    Transforms the result by ensuring the First_Name column contains\n",
    "    single words\"\"\"\n",
    "    result = client.sqllike(query)\n",
    "    df = pd.DataFrame.from_records(data=result.rows(), columns=result.header)\n",
    "    df['First_Name'] = df['First_Name'].transform(lambda x: re.split(r'[ -]', x)[0])\n",
    "    return df\n",
    "\n",
    "    \n",
    "with VisierSession(auth) as s:\n",
    "    query_client = QueryApiClient(s)\n",
    "    [f_df, m_df] = [mk_df(query_client, f\"\"\"SELECT EmployeeID,\n",
    "                                                   First_Name\n",
    "                                            FROM Employee\n",
    "                                            WHERE {concept}=TRUE AND Visier_Time BETWEEN date('2021-01-01') AND date('2022-01-01')\"\"\") for concept in [\"isFemale\", \"isMale\"]]\n",
    "    f_df['Gender'] = 'F'\n",
    "    m_df['Gender'] = 'M'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55d276e-de82-41ea-91c5-12c4e0665881",
   "metadata": {},
   "source": [
    "## Prepare the Data Set to Upload\n",
    "We now have two distinct data sets: the Visier `Employee` data and the SSA name ranking data. We can now bring them together to add Name_Rank data to the Visier `Employee` data.\n",
    "Handling the two gender designations independently, we join the Visier data with the SSA data set after ensuring the Visier data set has been suitably indexed to enable an `inner` join at the correct level of granularity.\n",
    "\n",
    "### EventDate\n",
    "After concatenating the two data sets, we add a column named `EventDate` and give it a date string in `yyyy-MM-dd` format. In this sample, we choose the value `yesterday`. The `yesterday` value means that employees whose first names were found in the SSA data set will have their current state record ended and immediately followed by a new record that reflects the change.\n",
    "\n",
    "### Filename\n",
    "After updating the DataFrame, we save it to a file that will upload to Visier in the next step. In this case, where we upload the file as is, the name of the file itself doesn't matter. However, if the data set is large enough to need compression, such as through a `.zip` archive, the name of the file inside the archive matters. In this case, because we are augmenting the data of an object that is primarily loaded through other methods, we must name the file after the target object name with the suffix `DDIExt`. In this example, the filename is `EmployeeDDIExt.csv`\n",
    "\n",
    "**Note**: If using the DDI API with a Primary data intake mode (that is, DDI API is the main data transfer method), the name of the file inside the compressed archive (such as a ZIP file) must match the name of the target object; for example, `Employee.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b50b6b5c-12ed-4761-98e8-45540e01a27b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def do_join(visier_df, ssa_df):\n",
    "    result=visier_df.set_index(['First_Name', 'Gender']).join(ssa_df, how='inner')\n",
    "    return result.reset_index()[['EmployeeID', 'Name_Rank']]\n",
    "\n",
    "# Build each gender result and combine\n",
    "f_result=do_join(f_df, f_names)\n",
    "m_result=do_join(m_df, m_names)\n",
    "result=pd.concat([f_result, m_result])\n",
    "\n",
    "# Data Set requires column `EventDate` with the date of the change\n",
    "yesterday = datetime.datetime.now() - datetime.timedelta(days=1)\n",
    "yesterday_str = yesterday.strftime('%Y-%m-%d')\n",
    "result['EventDate'] = yesterday_str\n",
    "\n",
    "# Write to file to be uploaded below\n",
    "result_filename='EmployeeDDIExt.csv'\n",
    "result.to_csv(result_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cfc8c-336f-4b7e-8953-631f98119fb0",
   "metadata": {},
   "source": [
    "## Upload the Data Set with the Direct Data Intake API\n",
    "To upload the data, we use the Python connector, which is instantiated in the same way that was described above.\n",
    "\n",
    "However, the initialization differs when instantiating a different API client, that is, the `DirectIntakeApiClient`.\n",
    "\n",
    "In this sample, we assume that most Visier customers use other means of sending data to Visier, such as SFTP or data connectors, which are processed in Visier's data provisioning engine. Because of this assumption, this sample uses the Direct Data Intake API to supplement existing data in Visier and extend the `Employee` object. Because the Supplemental data intake mode is not the default mode, we must configure the data intake mode for this data upload.\n",
    "\n",
    "### Upload Transaction\n",
    "The DDI API uses a transactional process that allows callers to upload many data files before sending the files to Visier. In this sample, we are sending one data file to Visier. To send our data file to Visier, the DDI API requires three calls:\n",
    "* `start_transaction` to begin a transaction. The response contains the transaction ID, which we must retain for the next two calls.\n",
    "* `upload_file` to specify a target object and provide a data file with columns that match the properties of the target object that we want to load.\n",
    "* `commit_transaction` to close the transaction and process the data files in Visier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f6f8dd-5a11-440b-a4fa-9a5e3d2e26a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from visier.api import DirectIntakeApiClient\n",
    "from visier.api.direct_intake import Configuration\n",
    "\n",
    "with VisierSession(auth) as s:\n",
    "    intake_client = DirectIntakeApiClient(s, raise_on_error=True)\n",
    "\n",
    "    # Configure the Direct Intake to supplement data in the tenant\n",
    "    # Enable loading into Employee using extension tables\n",
    "    config = Configuration(is_supplemental=True,\n",
    "                           extend_objects=['Employee'])\n",
    "    returned_config = intake_client.set_configuration(config)\n",
    "    \n",
    "    # Upload the file within the context of a transaction\n",
    "    try:\n",
    "        tx_response = intake_client.start_transaction().json()\n",
    "        print(tx_response)\n",
    "        transaction_id = tx_response['transactionId']\n",
    "        intake_client.upload_file(transaction_id, 'Employee', result_filename)\n",
    "        intake_client.commit_transaction(transaction_id)\n",
    "        print(f'Committed {transaction_id}')\n",
    "    except Exception as ex:\n",
    "        print(f'Rolling back {transaction_id}', ex)\n",
    "        intake_client.rollback_transaction(transaction_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9bff0-32d9-41fc-923b-76e06ffee8cd",
   "metadata": {},
   "source": [
    "Once the provisioning is complete, the data is available to query."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:visier-api]",
   "language": "python",
   "name": "conda-env-visier-api-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
