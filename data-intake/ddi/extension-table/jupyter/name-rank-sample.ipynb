{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1bdd0ef9-bd98-4ef2-8e25-056c8e6b8485",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Enriching the Visier Model\n",
    "## Overview\n",
    "This is a Jupyter Notebook sample that shows how to enrich the data in an analytic object which is primarily loaded from other sources.\n",
    "This sample in of itself has no intrinsic business value. Instead, its purpose is exclusively to show how to call various Visier Public APIs to query for source data, combine it with an external data set and finally, to write back the results.\n",
    "\n",
    "Specifically, we will be combining Visier Employee data with [publicly available name data](https://www.ssa.gov/oact/babynames/limits.html) from the US Government Social Security Administration for the purposes of populating a new `Employee` property called `Name_Rank`.\n",
    "\n",
    "### Prerequisites\n",
    "In order to run this example, the following prerequisites must be satisfied:\n",
    "1. Create and publish to production a simple, numeric property named `Name_Rank` on the `Employee` object\n",
    "1. Define and assign a profile that enables writing data and reading model metadata through APIs. In addition the following Capabilities are needed:\n",
    "   1. Direct Publish\n",
    "   1. Legacy API Access\n",
    "   1. Manage Jobs\n",
    "   1. Upload Data\n",
    "1. Defined an `.env` file as outlined in the [Python Connector documentation](https://github.com/visier/connector-python#jupyter-basic-authentication-example)\n",
    "1. Downloaded the [National Data names file](https://www.ssa.gov/oact/babynames/names.zip) from SSA and extracted file `yob2022.txt` and copied it into a directory named `data`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902780aa-da53-4911-8f7e-c8a4ef61dddd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Enrichment Data\n",
    "We use the ubiquitous `pandas` library both to represent data sets through `Dataframe`s as well as for file handling. The source files are comma-separated so we load it through the `read_csv` method.\n",
    "The file does not contain a header row, so we provide a header with names that will align with names of Visier properties. We perform very simple transformation where we sort the results by occurrence of each name and assign the rank based on row number of the sorted lists.\n",
    "We also define an index to facilitate a subsequent join-operation with Visier `Employee` data.\n",
    "\n",
    "As we will be simplifying the gender designations on the Visier side to match the SSA data, we create two distinct SSA name data sets: `f_names` and `m_names`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "59a0d7cc-c739-43a4-a761-c363fe4038aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def filter_and_index(df, gender):\n",
    "    df.loc[df['Gender'] == gender]\n",
    "    df['Name_Rank'] = df.reset_index().index + 1\n",
    "    return df.set_index(['First_Name', 'Gender'])\n",
    "\n",
    "names = pd.read_csv('data/yob2022.txt', header=0, names=['First_Name', 'Gender', 'Count'])\n",
    "names.sort_values(inplace=True, by='Count', ascending=False)\n",
    "f_names = filter_and_index(names, 'F')\n",
    "m_names = filter_and_index(names, 'M')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de6df0f-fb1c-46c7-9ebe-b31c1f574e57",
   "metadata": {},
   "source": [
    "## Query for Employee Data\n",
    "At this point, we are ready to instantiate the Visier Python Connector. We read credentials, build an `auth` object which we use to login to Visier and get a session object, `s`.\n",
    "Because we need to execute a Visier SQL-like query to get the list of `Employee`s whose name we wish to rank in this sample, we import the `QueryApiClient`.\n",
    "\n",
    "Gender designation for the Visier `Employee` object is completely customizable and in order to ensure we can align with the SSA-sourced data, we're going to execute two distinct but similar SQL-like queries; where `isFemale` is `TRUE` and when it is `FALSE`. Once we have these two distinct data sets, we manually ascribe the identical gender keys that is present in the SSA data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1b8fe6ec-4936-4db6-820f-f4da002daf8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from dotenv import dotenv_values\n",
    "from visier.connector import VisierSession, make_auth\n",
    "from visier.api import QueryApiClient\n",
    "\n",
    "env_creds=dotenv_values()\n",
    "auth = make_auth(env_values=env_creds)\n",
    "\n",
    "def mk_df(client, query):\n",
    "    \"\"\"Run a list query and return the results as a Pandas DataFrame.\n",
    "    Transforms the result by ensuring the First_Name column contains\n",
    "    single words\"\"\"\n",
    "    result = client.sqllike(query)\n",
    "    df = pd.DataFrame.from_records(data=result.rows(), columns=result.header)\n",
    "    df['First_Name'] = df['First_Name'].transform(lambda x: re.split(r'[ -]', x)[0])\n",
    "    return df\n",
    "\n",
    "    \n",
    "with VisierSession(auth) as s:\n",
    "    query_client = QueryApiClient(s)\n",
    "    [f_df, m_df] = [mk_df(query_client, f\"\"\"SELECT EmployeeID,\n",
    "                                                   First_Name\n",
    "                                            FROM Employee\n",
    "                                            WHERE isFemale={is_female} AND Visier_Time BETWEEN date('2021-01-01') AND date('2022-01-01')\"\"\") for is_female in [\"TRUE\", \"FALSE\"]]\n",
    "    f_df['Gender'] = 'F'\n",
    "    m_df['Gender'] = 'M'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55d276e-de82-41ea-91c5-12c4e0665881",
   "metadata": {},
   "source": [
    "## Prepare the Data Set to upload\n",
    "We now have two distinct data sets, the Visier `Employee` data and the SSA name ranking data and it is time to bring them together.\n",
    "Handling the two gender designations independently, we join the Visier data with the SSA data set after ensuring the Visier data set has been suitably indexed to enable an `inner` join at the correct level of granularity.\n",
    "\n",
    "### EventDate\n",
    "Once we have concatenated the two data sets, we have to perform one more transformation on the result: We have to add a column named `EventDate` and give it a date string value formatted like `yyyy-MM-dd`. We choose the value of 'yesterday' here. That we picked 'yesterday' is not important. What is important is to understand how this value impacts you `Employee` object's data. The employees whose first names were found in the SSA data set, will have their current state record ended and immediately followed by a new record that reflects the change.\n",
    "\n",
    "### Filename\n",
    "Once the Dataframe has been updated, we save it to a file that will uploaded to Visier in the next step. In this case, where we simply upload the file as is, the name of the file itself is not important. However, should the data set be large enough to merit compression, such as through a `.zip` archive, the name of the file _inside_ the archive matters. In this case, because we are augmenting the data of an object which is primarily loaded through other means (after all, we're just adding a name rank to the `Employee`), we would have to name the file after the target object name followed by the suffix `DDIExt`. That's why the file is named `EmployeeDDIExt.csv` so that it could be added to a compressed archive and still work.\n",
    "If, the other hand, we were loading objects directly, that is the Direct Intake API is used as the main source for data, the name of the file _inside_ the archive should match the name of the target object, for example `Employee.csv`,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b50b6b5c-12ed-4761-98e8-45540e01a27b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "def do_join(visier_df, ssa_df):\n",
    "    result=visier_df.set_index(['First_Name', 'Gender']).join(ssa_df, how='inner')\n",
    "    return result.reset_index()[['EmployeeID', 'Name_Rank']]\n",
    "\n",
    "# Build each gender result and combine\n",
    "f_result=do_join(f_df, f_names)\n",
    "m_result=do_join(m_df, m_names)\n",
    "result=pd.concat([f_result, m_result])\n",
    "\n",
    "# Data Set requires column `EventDate` with the date of the change\n",
    "yesterday = datetime.datetime.now() - datetime.timedelta(days=1)\n",
    "yesterday_str = yesterday.strftime('%Y-%m-%d')\n",
    "result['EventDate'] = yesterday_str\n",
    "\n",
    "# Write to file to be uploaded below\n",
    "result_filename='EmployeeDDIExt.csv'\n",
    "result.to_csv(result_filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7cfc8c-336f-4b7e-8953-631f98119fb0",
   "metadata": {},
   "source": [
    "## Upload the Data Set using the Direct Intake API\n",
    "When uploading data, we again use the Python connector. It is instantiated and initialized the same way as we did above in order to query for Visier data.\n",
    "\n",
    "### Direct Intake API\n",
    "The differences start with instantiating a different API client, namely the `DirectIntakeApiClient`.\n",
    "\n",
    "This specific sample is targeted to customers who use other means of loading the bulk of their data, such as uploading source files via SFTP which will be processed by the Visier Data Provisioning engine. Because we're using the Direct Intake API in a data supplementary fashion in general and augmenting `Employee` in particular, we have to provide `Configuration` that reflects that.\n",
    "\n",
    "### Upload Transaction\n",
    "Direct Intake API offers a transactional interface. This allows callers to upload many files before committing them to the system. In this case, we only have one data file, the we need three calls to upload and process one file:\n",
    "* `start_transaction` to begin a transaction. We have to retain the transaction ID returned from this function.\n",
    "* `upload_file` lets us point to a target object and provide a file with data that matches the appropriate sub set of properties that exist on said object.\n",
    "* `commit_transaction` closes the transaction to additional upload requests and intiates the processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f6f8dd-5a11-440b-a4fa-9a5e3d2e26a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from visier.api import DirectIntakeApiClient\n",
    "from visier.api.direct_intake import Configuration\n",
    "\n",
    "with VisierSession(auth) as s:\n",
    "    intake_client = DirectIntakeApiClient(s, raise_on_error=True)\n",
    "\n",
    "    # Configure the Direct Intake to supplement data in the tenant\n",
    "    # Enable loading into Employee using extension tables\n",
    "    config = Configuration(is_supplemental=True,\n",
    "                           extend_objects=['Employee'])\n",
    "    returned_config = intake_client.set_configuration(config)\n",
    "    \n",
    "    # Upload the file within the context of a transaction\n",
    "    try:\n",
    "        tx_response = intake_client.start_transaction().json()\n",
    "        print(tx_response)\n",
    "        transaction_id = tx_response['transactionId']\n",
    "        intake_client.upload_file(transaction_id, 'Employee', result_filename)\n",
    "        intake_client.commit_transaction(transaction_id)\n",
    "        print(f'Committed {transaction_id}')\n",
    "    except Exception as ex:\n",
    "        print(f'Rolling back {transaction_id}', ex)\n",
    "        intake_client.rollback_transaction(transaction_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a9bff0-32d9-41fc-923b-76e06ffee8cd",
   "metadata": {},
   "source": [
    "Once the provisioning is complete, the data is available to query."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:visier-api]",
   "language": "python",
   "name": "conda-env-visier-api-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
